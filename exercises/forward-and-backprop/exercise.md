# Exercise 

# Q1: Forward pass 

1. Forward to hidden layer



2. Apply sigmoid



3. Calculate the input to the output layer:



4. Calculate the final prediction 




# Q2: Backprop

1. Compute the gradient of the output layer



2. Compute the gradient of the hidden layer with respect to the weights 



3. Compute the gradient of hidden layer 



4. Compute the gradient of the input layer with respect to the weights 



5. Update the weights with gradient decent based on all the gradients 



# Group session questions

What is the primary purpose of the activation function in a neural network?
- We want to activate a neuron based on the input sum
- By choosing a activation result 


In the context of neural networks, what is the chain rule used for?
- Used in back propagation 
- We use it to show have some values update the weights 


Show chainrule for a given node with respect to another : 
- Resource: https://tutorial.math.lamar.edu/classes/calciii/chainrule.aspx